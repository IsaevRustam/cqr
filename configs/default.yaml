# CQR Experiment Configuration
# =============================

# Core experiment parameters
alpha: 0.05          # Miscoverage level (1-α = coverage)
beta: 1.0            # Hölder smoothness (fixed at 1 for now)
d: 1                 # Input dimension: 1, 2, or 4
seed: 42             # Random seed for reproducibility

# Monte Carlo settings
n_attempts: 50       # Number of Monte Carlo repetitions

# Neural network settings
hidden_dim: 32       # Hidden layer width
train_epochs: 200    # Training epochs
learning_rate: 0.01  # Adam learning rate

# Sample size grid (for convergence experiments)
# Grid is based on training sample size n, calibration m = n^c
n_train_grid_start: 100
n_train_grid_end: 10000
n_train_grid_num: 15

# Fixed sample size (for localized experiments)
n_fixed: 200000

# Bandwidth scale factor for localized CQR
# Inflates bandwidth h = scale * m^{-1/(2γ+d)} to ensure neighbors in sparse regions
bandwidth_scale: 0.8

# Calibration size multiplier for global CQR (m = C * n^c)
# Ensures sufficient samples for quantile estimation while maintaining asymptotic rate
calibration_scale_c: 1.0

# Calibration exponent: controls relationship m = C * n^c
# Default 0.5 gives m = O(sqrt(n))
calibration_exponent: 1.0

# Test set size
n_test: 100000

# Output directory
output_dir: "."
